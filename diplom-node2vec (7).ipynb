{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8403722,"sourceType":"datasetVersion","datasetId":5000516}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport networkx as nx\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.image as mpimg\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-15T08:40:18.101241Z","iopub.execute_input":"2024-05-15T08:40:18.102570Z","iopub.status.idle":"2024-05-15T08:40:18.111127Z","shell.execute_reply.started":"2024-05-15T08:40:18.102503Z","shell.execute_reply":"2024-05-15T08:40:18.109569Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_excel('/kaggle/input/vitrina/vitrina_clusters.xlsx')\ndataset = dataset[:400]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:40:20.780773Z","iopub.execute_input":"2024-05-15T08:40:20.781197Z","iopub.status.idle":"2024-05-15T08:41:11.575698Z","shell.execute_reply.started":"2024-05-15T08:40:20.781166Z","shell.execute_reply":"2024-05-15T08:41:11.574374Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[\"cluster\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf1 = dataset[dataset['cluster'] == 0]\n#df2 = dataset[dataset['cluster'] == 1]\n#df3 = dataset[dataset['cluster'] == 2]\ndf4 = dataset[dataset['cluster'] == 3]\ndf5 = dataset[dataset['cluster'] == 4]\ndf6 = dataset[dataset['cluster'] == 5]\n\nX1_train, X1_test = train_test_split(df1,test_size=0.2, random_state=42)\n#X2_train, X2_test = train_test_split(df2,test_size=0.2, random_state=42)\n#X3_train, X3_test = train_test_split(df3,test_size=0.2, random_state=42)\nX4_train, X4_test = train_test_split(df4,test_size=0.2, random_state=42)\nX5_train, X5_test = train_test_split(df5,test_size=0.2, random_state=42)\nX6_train, X6_test = train_test_split(df6,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:41:15.610515Z","iopub.execute_input":"2024-05-15T08:41:15.611601Z","iopub.status.idle":"2024-05-15T08:41:15.634103Z","shell.execute_reply.started":"2024-05-15T08:41:15.611549Z","shell.execute_reply":"2024-05-15T08:41:15.632660Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def creating_graph(dataset):\n    G = nx.Graph()\n    node2index = {}\n    node_counter = 0\n    \n    some_unique_id = \"000-000\"\n    G.add_node(node_counter,type='user') #- вершина для тестового набора данных\n    node2index[some_unique_id] = node_counter\n    node_counter += 1\n    \n    items = ['%TN_Автотовары', '%TN_Аксессуары', '%TN_Детские товары', '%TN_Игры, софт и развлечения', '%TN_Климат', '%TN_Крупная бытовая техника', '%TN_Мебель', '%TN_Мелкая бытовая техника', '%TN_Сделай сам', '%TN_Спорт и активный отдых', '%TN_ТВ-Аудио', '%TN_Товары для дома', '%TN_Услуги', '%TN_Хобби, досуг', '%TN_Цифровая Техника', '%TN_Элитная техника']\n    \n    for i in items:\n        G.add_node(node_counter, type='item')\n        node2index[i] = node_counter\n        node_counter += 1\n    \n    for index, row in dataset.iterrows():\n        G.add_node(node_counter, type='user')\n        node2index[row['Phone_new']] = node_counter\n        for i in items:\n            G.add_edge(node_counter, node2index[i], weight=row[i])\n        node_counter += 1\n    \n    return G, node2index\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:41:19.053563Z","iopub.execute_input":"2024-05-15T08:41:19.054671Z","iopub.status.idle":"2024-05-15T08:41:19.064805Z","shell.execute_reply.started":"2024-05-15T08:41:19.054632Z","shell.execute_reply":"2024-05-15T08:41:19.063706Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def biased_random_walk(G, start_node, walk_length, p=1, q=1):\n    walk = [start_node]\n\n    while len(walk) < walk_length:\n        cur_node = walk[-1]\n        cur_neighbors = list(G.neighbors(cur_node))\n\n        if len(cur_neighbors) > 0:\n            if len(walk) == 1:\n                walk.append(random.choice(cur_neighbors))\n            else:\n                prev_node = walk[-2]\n\n                probability = []\n                for neighbor in cur_neighbors:\n                    if neighbor == prev_node:\n                        # Return parameter \n                        probability.append(1/p)\n                    elif G.has_edge(neighbor, prev_node):\n                        # Stay parameter \n                        probability.append(1)\n                    else:\n                        # In-out parameter \n                        probability.append(1/q)\n\n                probability = np.array(probability)\n                probability = probability / probability.sum()  # normalize\n\n                next_node = np.random.choice(cur_neighbors, p=probability)\n                walk.append(next_node)\n        else:\n            break\n\n    return walk","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:50:20.961892Z","iopub.execute_input":"2024-05-15T07:50:20.962522Z","iopub.status.idle":"2024-05-15T07:50:20.972877Z","shell.execute_reply.started":"2024-05-15T07:50:20.962488Z","shell.execute_reply":"2024-05-15T07:50:20.971443Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generate_walks(G, num_walks, walk_length, p=1, q=1):\n    walks = []\n    nodes = list(G.nodes())\n    for _ in range(num_walks):\n        random.shuffle(nodes)  # to ensure randomness\n        for node in nodes:\n            walk_from_node = biased_random_walk(G, node, walk_length, p, q)\n            walks.append(walk_from_node)\n    return walks","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:50:23.397073Z","iopub.execute_input":"2024-05-15T07:50:23.397452Z","iopub.status.idle":"2024-05-15T07:50:23.404208Z","shell.execute_reply.started":"2024-05-15T07:50:23.397408Z","shell.execute_reply":"2024-05-15T07:50:23.402965Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#!pip install pygsp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def creating_model(G):\n    walks = generate_walks(G, num_walks=10, walk_length=20, p=9, q=1)\n    filtered_walks = [walk for walk in walks if len(walk) >= 5]\n\n    # to String  (for Word2Vec input)\n    walks = [[str(node) for node in walk] for walk in walks]\n\n    # Word2Vec train\n    model = Word2Vec(walks, vector_size=128, window=5, min_count=0,  hs=1, sg=1, workers=4, epochs=10)\n\n    # node embedding extract\n    embeddings = {node_id: model.wv[node_id] for node_id in model.wv.index_to_key}\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:50:25.691025Z","iopub.execute_input":"2024-05-15T07:50:25.691427Z","iopub.status.idle":"2024-05-15T07:50:25.699421Z","shell.execute_reply.started":"2024-05-15T07:50:25.691396Z","shell.execute_reply":"2024-05-15T07:50:25.698350Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"G1, node_index1 = creating_graph(X1_train)\nG4, node_index4 = creating_graph(X4_train)\nG5, node_index5 = creating_graph(X5_train)\nG6, node_index6 = creating_graph(X6_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:41:23.823679Z","iopub.execute_input":"2024-05-15T08:41:23.824204Z","iopub.status.idle":"2024-05-15T08:41:23.932223Z","shell.execute_reply.started":"2024-05-15T08:41:23.824165Z","shell.execute_reply":"2024-05-15T08:41:23.930700Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model1 = creating_model(G1)\nmodel4 = creating_model(G4)\nmodel5 = creating_model(G5)\nmodel6 = creating_model(G6)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:30:23.049838Z","iopub.execute_input":"2024-05-15T08:30:23.050339Z","iopub.status.idle":"2024-05-15T08:30:36.967331Z","shell.execute_reply.started":"2024-05-15T08:30:23.050299Z","shell.execute_reply":"2024-05-15T08:30:36.965884Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"embeddings1 = {node_id: model1.wv[node_id] for node_id in model1.wv.index_to_key}\nembeddings4 = {node_id: model4.wv[node_id] for node_id in model4.wv.index_to_key}\nembeddings5 = {node_id: model5.wv[node_id] for node_id in model5.wv.index_to_key}\nembeddings6 = {node_id: model6.wv[node_id] for node_id in model6.wv.index_to_key}","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:30:46.187877Z","iopub.execute_input":"2024-05-15T08:30:46.188294Z","iopub.status.idle":"2024-05-15T08:30:46.196727Z","shell.execute_reply.started":"2024-05-15T08:30:46.188256Z","shell.execute_reply":"2024-05-15T08:30:46.195596Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def get_user_embedding(user_id, embeddings):\n    return embeddings[str(user_id)]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:02:38.883312Z","iopub.execute_input":"2024-05-15T09:02:38.884292Z","iopub.status.idle":"2024-05-15T09:02:38.889908Z","shell.execute_reply.started":"2024-05-15T09:02:38.884256Z","shell.execute_reply":"2024-05-15T09:02:38.888508Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"def get_rated_items(user_id, df, item, items):\n    return df[df['Phone_new'] == user_id][item]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:02:40.448375Z","iopub.execute_input":"2024-05-15T09:02:40.449654Z","iopub.status.idle":"2024-05-15T09:02:40.455655Z","shell.execute_reply.started":"2024-05-15T09:02:40.449607Z","shell.execute_reply":"2024-05-15T09:02:40.454624Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def calculate_similarities(user_id, df, embeddings, items):\n    for item in items:\n        rated_items = get_rated_items(user_id, df, item, items)\n    user_embedding = get_user_embedding(user_id, embeddings)\n\n    item_similarities = []\n    for item_id in items:\n        if item_id not in rated_items:  \n            item_embedding = embeddings[item_id]\n            similarity = cosine_similarity([user_embedding], [item_embedding])[0][0]\n            item_similarities.append((item_id, similarity))\n\n    return item_similarities","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:02:41.979590Z","iopub.execute_input":"2024-05-15T09:02:41.980014Z","iopub.status.idle":"2024-05-15T09:02:41.988635Z","shell.execute_reply.started":"2024-05-15T09:02:41.979981Z","shell.execute_reply":"2024-05-15T09:02:41.987048Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def recommend_items(user_id, df, embeddings, items, num_items=5):\n    for item in items:\n        rated_items = get_rated_items(user_id, df, item, items)\n    \n    #print(f\"User {user_id} has purchased:\")\n    #print(rated_items)\n    \n    item_similarities = calculate_similarities(user_id, df, embeddings, items)\n\n    recommended_items = sorted(item_similarities, key=lambda x: x[1], reverse=True)[:num_items]\n\n    #print(f\"\\nRecommended items for user {user_id}:\")\n    #print(recommended_items)\n    return recommended_items","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:02:44.078912Z","iopub.execute_input":"2024-05-15T09:02:44.079337Z","iopub.status.idle":"2024-05-15T09:02:44.086930Z","shell.execute_reply.started":"2024-05-15T09:02:44.079305Z","shell.execute_reply":"2024-05-15T09:02:44.085475Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"items = ['%TN_Автотовары', '%TN_Аксессуары', '%TN_Детские товары', '%TN_Игры, софт и развлечения', '%TN_Климат', '%TN_Крупная бытовая техника', '%TN_Мебель', '%TN_Мелкая бытовая техника', '%TN_Сделай сам', '%TN_Спорт и активный отдых', '%TN_ТВ-Аудио', '%TN_Товары для дома', '%TN_Услуги', '%TN_Хобби, досуг', '%TN_Цифровая Техника', '%TN_Элитная техника']\nrecommends1 = recommend_items(0, df1, embeddings1, items, num_items=16)\nrecommends4 = recommend_items(0, df4, embeddings4, items, num_items=16)\nrecommends5 = recommend_items(0, df5, embeddings5, items, num_items=16)\nrecommends6 = recommend_items(0, df6, embeddings6, items, num_items=16)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:51:02.738283Z","iopub.execute_input":"2024-05-15T07:51:02.738768Z","iopub.status.idle":"2024-05-15T07:51:02.848692Z","shell.execute_reply.started":"2024-05-15T07:51:02.738732Z","shell.execute_reply":"2024-05-15T07:51:02.847510Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"recommends1, recommends4, recommends5, recommends6","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:51:05.699668Z","iopub.execute_input":"2024-05-15T07:51:05.700089Z","iopub.status.idle":"2024-05-15T07:51:05.715776Z","shell.execute_reply.started":"2024-05-15T07:51:05.700054Z","shell.execute_reply":"2024-05-15T07:51:05.714524Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"([('%TN_Мебель', -0.042497084),\n  ('%TN_Цифровая Техника', -0.044116154),\n  ('%TN_Услуги', -0.04779979),\n  ('%TN_Мелкая бытовая техника', -0.05211915),\n  ('%TN_Сделай сам', -0.059032157),\n  ('%TN_Хобби, досуг', -0.0657479),\n  ('%TN_Игры, софт и развлечения', -0.06897238),\n  ('%TN_Элитная техника', -0.071771085),\n  ('%TN_ТВ-Аудио', -0.08191761),\n  ('%TN_Товары для дома', -0.082805365),\n  ('%TN_Автотовары', -0.08413016),\n  ('%TN_Аксессуары', -0.0917189),\n  ('%TN_Детские товары', -0.09410525),\n  ('%TN_Крупная бытовая техника', -0.10168506),\n  ('%TN_Климат', -0.10394407),\n  ('%TN_Спорт и активный отдых', -0.108910866)],\n [('%TN_Услуги', 0.07887531),\n  ('%TN_Игры, софт и развлечения', 0.078257084),\n  ('%TN_Автотовары', 0.07665241),\n  ('%TN_Климат', 0.076492615),\n  ('%TN_Мебель', 0.0764764),\n  ('%TN_Мелкая бытовая техника', 0.074820966),\n  ('%TN_Элитная техника', 0.07424072),\n  ('%TN_Сделай сам', 0.07284645),\n  ('%TN_Крупная бытовая техника', 0.072159186),\n  ('%TN_Цифровая Техника', 0.071164414),\n  ('%TN_Аксессуары', 0.07067545),\n  ('%TN_Хобби, досуг', 0.0701314),\n  ('%TN_Детские товары', 0.07006973),\n  ('%TN_ТВ-Аудио', 0.06894472),\n  ('%TN_Товары для дома', 0.06589223),\n  ('%TN_Спорт и активный отдых', 0.06584907)],\n [('%TN_ТВ-Аудио', 0.094174705),\n  ('%TN_Цифровая Техника', 0.09222646),\n  ('%TN_Товары для дома', 0.09106584),\n  ('%TN_Спорт и активный отдых', 0.09016991),\n  ('%TN_Крупная бытовая техника', 0.089545935),\n  ('%TN_Игры, софт и развлечения', 0.08913889),\n  ('%TN_Климат', 0.08700034),\n  ('%TN_Хобби, досуг', 0.08669823),\n  ('%TN_Сделай сам', 0.0865559),\n  ('%TN_Элитная техника', 0.08607288),\n  ('%TN_Мебель', 0.08595896),\n  ('%TN_Детские товары', 0.084029555),\n  ('%TN_Мелкая бытовая техника', 0.083567955),\n  ('%TN_Услуги', 0.082392395),\n  ('%TN_Аксессуары', 0.08180516),\n  ('%TN_Автотовары', 0.08166793)],\n [('%TN_Спорт и активный отдых', -0.010566924),\n  ('%TN_Крупная бытовая техника', -0.018042559),\n  ('%TN_Услуги', -0.018687874),\n  ('%TN_Автотовары', -0.019821089),\n  ('%TN_Хобби, досуг', -0.02070057),\n  ('%TN_Товары для дома', -0.021812702),\n  ('%TN_Элитная техника', -0.022286791),\n  ('%TN_Климат', -0.02981732),\n  ('%TN_Детские товары', -0.03045173),\n  ('%TN_Мебель', -0.031179909),\n  ('%TN_Цифровая Техника', -0.031702142),\n  ('%TN_ТВ-Аудио', -0.032429952),\n  ('%TN_Игры, софт и развлечения', -0.03377208),\n  ('%TN_Сделай сам', -0.033977665),\n  ('%TN_Аксессуары', -0.034688212),\n  ('%TN_Мелкая бытовая техника', -0.04072406)])"},"metadata":{}}]},{"cell_type":"code","source":"X1_test[items]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:51:10.949100Z","iopub.execute_input":"2024-05-15T07:51:10.949924Z","iopub.status.idle":"2024-05-15T07:51:10.992212Z","shell.execute_reply.started":"2024-05-15T07:51:10.949860Z","shell.execute_reply":"2024-05-15T07:51:10.991163Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"     %TN_Автотовары  %TN_Аксессуары  %TN_Детские товары  \\\n59              0.0            60.0                 0.0   \n197             0.0             0.0                 0.0   \n70              0.0             0.0                 0.0   \n30              0.0           100.0                 0.0   \n137             0.0             0.0                 0.0   \n..              ...             ...                 ...   \n306             0.0             0.0                 0.0   \n10              0.0             0.0                 0.0   \n390             0.0             0.0                 0.0   \n108             0.0             0.0                 0.0   \n358             0.0           100.0                 0.0   \n\n     %TN_Игры, софт и развлечения  %TN_Климат  %TN_Крупная бытовая техника  \\\n59                            0.0         0.0                          0.0   \n197                           0.0         0.0                          0.0   \n70                            0.0         0.0                          0.0   \n30                            0.0         0.0                          0.0   \n137                           0.0         0.0                          0.0   \n..                            ...         ...                          ...   \n306                           0.0         0.0                          0.0   \n10                            0.0         0.0                          0.0   \n390                           0.0         0.0                          0.0   \n108                           0.0         0.0                          0.0   \n358                           0.0         0.0                          0.0   \n\n     %TN_Мебель  %TN_Мелкая бытовая техника  %TN_Сделай сам  \\\n59          0.0                        20.0             0.0   \n197         0.0                       100.0             0.0   \n70          0.0                       100.0             0.0   \n30          0.0                         0.0             0.0   \n137         0.0                       100.0             0.0   \n..          ...                         ...             ...   \n306         0.0                         0.0             0.0   \n10          0.0                         0.0             0.0   \n390         0.0                       100.0             0.0   \n108         0.0                         0.0             0.0   \n358         0.0                         0.0             0.0   \n\n     %TN_Спорт и активный отдых  %TN_ТВ-Аудио  %TN_Товары для дома  \\\n59                          0.0           0.0                 20.0   \n197                         0.0           0.0                  0.0   \n70                          0.0           0.0                  0.0   \n30                          0.0           0.0                  0.0   \n137                         0.0           0.0                  0.0   \n..                          ...           ...                  ...   \n306                         0.0           0.0                100.0   \n10                          0.0         100.0                  0.0   \n390                         0.0           0.0                  0.0   \n108                         0.0           0.0                  0.0   \n358                         0.0           0.0                  0.0   \n\n     %TN_Услуги  %TN_Хобби, досуг  %TN_Цифровая Техника  %TN_Элитная техника  \n59          0.0                 0                   0.0                    0  \n197         0.0                 0                   0.0                    0  \n70          0.0                 0                   0.0                    0  \n30          0.0                 0                   0.0                    0  \n137         0.0                 0                   0.0                    0  \n..          ...               ...                   ...                  ...  \n306         0.0                 0                   0.0                    0  \n10          0.0                 0                   0.0                    0  \n390         0.0                 0                   0.0                    0  \n108         0.0                 0                 100.0                    0  \n358         0.0                 0                   0.0                    0  \n\n[68 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>%TN_Автотовары</th>\n      <th>%TN_Аксессуары</th>\n      <th>%TN_Детские товары</th>\n      <th>%TN_Игры, софт и развлечения</th>\n      <th>%TN_Климат</th>\n      <th>%TN_Крупная бытовая техника</th>\n      <th>%TN_Мебель</th>\n      <th>%TN_Мелкая бытовая техника</th>\n      <th>%TN_Сделай сам</th>\n      <th>%TN_Спорт и активный отдых</th>\n      <th>%TN_ТВ-Аудио</th>\n      <th>%TN_Товары для дома</th>\n      <th>%TN_Услуги</th>\n      <th>%TN_Хобби, досуг</th>\n      <th>%TN_Цифровая Техника</th>\n      <th>%TN_Элитная техника</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59</th>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>100.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>68 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import average_precision_score, ndcg_score\n\ndef calculate_map(true_relevance, relevance_score):\n    ap = average_precision_score(true_relevance, relevance_score)\n    map_metric = np.mean(ap)\n    return map_metric\n\ndef calculate_ndcg(true_relevance, relevance_score):\n    dcg = ndcg_score(true_relevance, relevance_score)\n    idcg = ndcg_score(true_relevance, true_relevance)\n    ndcg = dcg / idcg\n    return ndcg\n\n# Example usage\n# for i in items:\n#     if dataset[]\n# true_relevance = np.asarray(purchased)\n# relevance_score = np.asarray(recommends)\n\n# map_metric = calculate_map(true_relevance, relevance_score)\n# ndcg = calculate_ndcg(true_relevance, relevance_score)\n\n# print(\"MAP:\", map_metric)\n# print(\"NDCG:\", ndcg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"relevance_score1 = [x[1] for x in recommends1]\nrelevance_score1 = relevance_score1\nrelevance_score1","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:51:19.391540Z","iopub.execute_input":"2024-05-15T07:51:19.391908Z","iopub.status.idle":"2024-05-15T07:51:19.400141Z","shell.execute_reply.started":"2024-05-15T07:51:19.391878Z","shell.execute_reply":"2024-05-15T07:51:19.398971Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[-0.042497084,\n -0.044116154,\n -0.04779979,\n -0.05211915,\n -0.059032157,\n -0.0657479,\n -0.06897238,\n -0.071771085,\n -0.08191761,\n -0.082805365,\n -0.08413016,\n -0.0917189,\n -0.09410525,\n -0.10168506,\n -0.10394407,\n -0.108910866]"},"metadata":{}}]},{"cell_type":"code","source":"def map_at_k(scores, true_relevance, k):\n    \"\"\"\n    Calculates the Mean Average Precision at K (MAP@K) metric for a set of predictions.\n\n    Parameters:\n    scores (list of lists): A list of lists, where each inner list contains the predicted scores for a single user.\n    true_relevance (list of lists): A list of lists, where each inner list contains the true relevance for a single user.\n    k (int): The number of items to consider for each user.\n\n    Returns:\n    float: The MAP@K score.\n    \"\"\"\n    num_users = len(scores)\n    ap_scores = []\n\n    for i in range(num_users):\n        # Sort the predicted scores by value\n        sorted_scores = sorted(enumerate(scores[i]), key=lambda x: x[1], reverse=True)\n        # Get the top k predicted items\n        top_k_predicted_items = [x[0] for x in sorted_scores[:k]]\n        # Calculate the average precision\n        num_relevant_items = sum(1 for j in range(len(true_relevance[i])) if true_relevance[i][j] > 0)\n        relevant_count = 0\n        ap = 0\n        for j in range(k):\n            if true_relevance[i][top_k_predicted_items[j]] > 0:\n                relevant_count += 1\n                ap += relevant_count / (j + 1)\n        ap_scores.append(ap / min(num_relevant_items, k))\n\n    # Calculate the MAP@K score\n    map_k = np.mean(ap_scores)\n    return map_k","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:51:36.823578Z","iopub.execute_input":"2024-05-15T07:51:36.824001Z","iopub.status.idle":"2024-05-15T07:51:36.834941Z","shell.execute_reply.started":"2024-05-15T07:51:36.823967Z","shell.execute_reply":"2024-05-15T07:51:36.833680Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maps = []\nfor i in range(len(X1_test)):\n    true_relevance = X1_test[items].iloc[i].values.tolist()\n    for i in range(len(true_relevance)):\n        if true_relevance[i] > 0:\n            true_relevance[i] = 1\n    map_k = map_at_k([relevance_score1], [true_relevance], 10)\n    maps.append(map_k)\n# for i in range(len(maps)):\n#     if maps[i] == 0:\n#         maps[i] = 1\nnp.mean(maps)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:07:41.645684Z","iopub.execute_input":"2024-05-15T08:07:41.646085Z","iopub.status.idle":"2024-05-15T08:07:41.712942Z","shell.execute_reply.started":"2024-05-15T08:07:41.646054Z","shell.execute_reply":"2024-05-15T08:07:41.711504Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0.35929913632119514"},"metadata":{}}]},{"cell_type":"code","source":"import networkx as nx\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Define the GCN layer\nclass GCNLayer(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(GCNLayer, self).__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.xavier_uniform_(self.weight)\n        nn.init.zeros_(self.bias)\n\n    def forward(self, input, adj):\n        support = torch.matmul(input, self.weight)\n        output = torch.matmul(adj, support) + self.bias\n        return output\n\n# Define the GCN model\nclass GCN(nn.Module):\n    def __init__(self, n_features, n_hidden, n_classes):\n        super(GCN, self).__init__()\n        self.gc1 = GCNLayer(n_features, n_hidden)\n        self.relu = nn.ReLU()\n        self.gc2 = GCNLayer(n_hidden, n_classes)\n\n    def forward(self, x, adj):\n        x = self.gc1(x, adj)\n        x = self.relu(x)\n        x = self.gc2(x, adj)\n        return x\n\n# Create a graph using NetworkX\nG = G1\n\n# Convert the graph to a PyTorch tensor\n# добавить индексы \n#print([e[1] for e in G.edges()])\nedge_index = torch.tensor([[e[0] for e in G.edges()], [e[1] for e in G.edges()]])\n\n# Create the feature matrix\nfeatures = torch.randn(100, 10)\n\n# Convert the feature matrix to a PyTorch tensor\nx = torch.tensor(features.tolist())\n\n# Create the adjacency matrix\nadj = nx.adjacency_matrix(G).toarray()\n\n# Convert the adjacency matrix to a PyTorch tensor\nadj = torch.tensor(adj)\n\n# Create the GCN model\nmodel = GCN(10, 16, 4)\n\n# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Define the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(100):\n    optimizer.zero_grad()\n    output = model(x, adj)\n    loss = criterion(output, torch.randint(4, (100,)))\n    loss.backward()\n    optimizer.step()\n\n# Use the trained model to generate embeddings\nembeddings = model(x, adj)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:20:15.801492Z","iopub.execute_input":"2024-05-15T08:20:15.801975Z","iopub.status.idle":"2024-05-15T08:20:15.903255Z","shell.execute_reply.started":"2024-05-15T08:20:15.801940Z","shell.execute_reply":"2024-05-15T08:20:15.901770Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 43\u001b[0m\n\u001b[1;32m     38\u001b[0m G \u001b[38;5;241m=\u001b[39m G1\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Convert the graph to a PyTorch tensor\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# добавить индексы \u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#print([e[1] for e in G.edges()])\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Create the feature matrix\u001b[39;00m\n\u001b[1;32m     46\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"],"ename":"ValueError","evalue":"too many dimensions 'str'","output_type":"error"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport networkx as nx\nimport scipy.sparse as sp\n\nclass GraphAttentionLayer(nn.Module):\n    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n        super(GraphAttentionLayer, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.alpha = alpha\n        self.concat = concat\n        self.dropout = dropout\n        \n        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n        \n        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n        \n        self.leakyrelu = nn.LeakyReLU(self.alpha)\n        \n    def forward(self, input, adj):\n        print(\"Input shape:\", input.shape)\n        print(\"Adjacency matrix shape:\", adj.shape)\n        h = torch.matmul(input, self.W)\n        N = h.size()[0]\n        \n        a_input = torch.cat([h.repeat(1, N).view(N*N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2*self.out_features)\n        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n        \n        zero_vec = -9e15*torch.ones_like(e)\n        attention = torch.where(adj > 0, e, zero_vec)\n        attention = F.softmax(attention, dim=1)\n        attention = F.dropout(attention, self.dropout, training=self.training)\n        h_prime = torch.matmul(attention, h)\n        \n        if self.concat:\n            return F.elu(h_prime)\n        else:\n            return h_prime\n\nclass GAT(nn.Module):\n    def __init__(self, nfeat, nhid, nclass, dropout=0.6, alpha=0.2, nheads=8):\n        super(GAT, self).__init__()\n        self.dropout = dropout\n        \n        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n        for i, attention in enumerate(self.attentions):\n            self.add_module('attention_{}'.format(i), attention)\n        \n        self.out_att = GraphAttentionLayer(nhid*nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n        \n    def forward(self, x, adj):\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = F.elu(self.out_att(x, adj))\n        return F.log_softmax(x, dim=1)\n\n# Example usage\nG = G5\n# Generate a random graph using NetworkX\nadj = nx.adjacency_matrix(G)\n\n# Convert adjacency matrix to a PyTorch dense tensor\nadj_tensor = torch.FloatTensor(adj.todense())\n\n# Define node features (random in this example)\nnode_features = torch.randn(G.number_of_nodes(), 16) # Use the number of nodes from your graph\n\n# Initialize the GAT model\nmodel = GAT(nfeat=16, nhid=8, nclass=2, dropout=0.6, alpha=0.2, nheads=8)\n\n# Forward pass\n\nembeddings = model(node_features, adj_tensor)\nembeddings_dict = {node_id: embeddings[index].detach().numpy() for node_id, index in node_index5.items()}\n\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef recommend_items(user_id, embeddings_dict, top_n=10):\n    user_embedding = embeddings_dict[user_id]\n    item_embeddings = [embedding for node_id, embedding in embeddings_dict.items() if node_id != user_id and node_id.startswith('%')]\n    \n    similarities = cosine_similarity([user_embedding], item_embeddings)\n    top_indices = np.argsort(similarities[0])[::-1][:top_n]\n    \n    recommended_items = [(list(embeddings_dict.keys())[i], similarities[0][i]) for i in top_indices]\n    return recommended_items\n\n# Example usage\nuser_id = '000-000'  \nrecommended_items = recommend_items(user_id, embeddings_dict)\n\nmaps = []\nfor i in range(len(X5_test)):\n    true_relevance = X5_test[items].iloc[i].values.tolist()\n    for i in range(len(true_relevance)):\n        if true_relevance[i] > 0:\n            true_relevance[i] = 1\n    map_k = map_at_k([recommended_items], [true_relevance], 10)\n    maps.append(map_k)\n# for i in range(len(maps)):\n#     if maps[i] == 0:\n#         maps[i] = 1\nnp.mean(maps)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:14:35.615656Z","iopub.execute_input":"2024-05-15T09:14:35.616325Z","iopub.status.idle":"2024-05-15T09:14:35.667960Z","shell.execute_reply.started":"2024-05-15T09:14:35.616290Z","shell.execute_reply":"2024-05-15T09:14:35.666985Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Input shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 16])\nAdjacency matrix shape: torch.Size([19, 19])\nInput shape: torch.Size([19, 64])\nAdjacency matrix shape: torch.Size([19, 19])\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"0.6435626102292769"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}