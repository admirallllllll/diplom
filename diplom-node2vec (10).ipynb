{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8403722,"sourceType":"datasetVersion","datasetId":5000516}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport networkx as nx\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.image as mpimg\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-15T10:42:08.254253Z","iopub.execute_input":"2024-05-15T10:42:08.254647Z","iopub.status.idle":"2024-05-15T10:42:27.815128Z","shell.execute_reply.started":"2024-05-15T10:42:08.254608Z","shell.execute_reply":"2024-05-15T10:42:27.813719Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_excel('/kaggle/input/vitrina/vitrina_clusters.xlsx')\n#dataset = dataset[:400]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:42:27.823556Z","iopub.execute_input":"2024-05-15T10:42:27.824009Z","iopub.status.idle":"2024-05-15T10:43:19.804080Z","shell.execute_reply.started":"2024-05-15T10:42:27.823963Z","shell.execute_reply":"2024-05-15T10:43:19.802562Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[\"cluster\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:47:34.543700Z","iopub.execute_input":"2024-05-15T10:47:34.544160Z","iopub.status.idle":"2024-05-15T10:47:34.562167Z","shell.execute_reply.started":"2024-05-15T10:47:34.544124Z","shell.execute_reply":"2024-05-15T10:47:34.560658Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"cluster\n0    75394\n5    12730\n3      697\n4       60\n2        6\n1        1\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf1 = dataset[dataset['cluster'] == 0]\n#df2 = dataset[dataset['cluster'] == 1]\n#df3 = dataset[dataset['cluster'] == 2]\ndf4 = dataset[dataset['cluster'] == 3]\ndf5 = dataset[dataset['cluster'] == 4]\ndf6 = dataset[dataset['cluster'] == 5]\n\nX1_train, X1_test = train_test_split(df1,test_size=0.2, random_state=42)\n#X2_train, X2_test = train_test_split(df2,test_size=0.2, random_state=42)\n#X3_train, X3_test = train_test_split(df3,test_size=0.2, random_state=42)\nX4_train, X4_test = train_test_split(df4,test_size=0.2, random_state=42)\nX5_train, X5_test = train_test_split(df5,test_size=0.2, random_state=42)\nX6_train, X6_test = train_test_split(df6,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:44:52.777505Z","iopub.execute_input":"2024-05-15T10:44:52.778582Z","iopub.status.idle":"2024-05-15T10:44:52.880851Z","shell.execute_reply.started":"2024-05-15T10:44:52.778519Z","shell.execute_reply":"2024-05-15T10:44:52.879332Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def creating_graph(dataset):\n    G = nx.Graph()\n    node2index = {}\n    node_counter = 0\n    \n    some_unique_id = \"000-000\"\n    G.add_node(node_counter,type='user') #- вершина для тестового набора данных\n    node2index[some_unique_id] = node_counter\n    node_counter += 1\n    \n    items = ['%TN_Автотовары', '%TN_Аксессуары', '%TN_Детские товары', '%TN_Игры, софт и развлечения', '%TN_Климат', '%TN_Крупная бытовая техника', '%TN_Мебель', '%TN_Мелкая бытовая техника', '%TN_Сделай сам', '%TN_Спорт и активный отдых', '%TN_ТВ-Аудио', '%TN_Товары для дома', '%TN_Услуги', '%TN_Хобби, досуг', '%TN_Цифровая Техника', '%TN_Элитная техника']\n    \n    for i in items:\n        G.add_node(node_counter, type='item')\n        node2index[i] = node_counter\n        node_counter += 1\n    \n    for index, row in dataset.iterrows():\n        G.add_node(node_counter, type='user')\n        node2index[row['Phone_new']] = node_counter\n        for i in items:\n            G.add_edge(node_counter, node2index[i], weight=row[i])\n        node_counter += 1\n    \n    return G, node2index\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:44:55.203840Z","iopub.execute_input":"2024-05-15T10:44:55.204310Z","iopub.status.idle":"2024-05-15T10:44:55.215758Z","shell.execute_reply.started":"2024-05-15T10:44:55.204279Z","shell.execute_reply":"2024-05-15T10:44:55.214262Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def biased_random_walk(G, start_node, walk_length, p=1, q=1):\n    walk = [start_node]\n\n    while len(walk) < walk_length:\n        cur_node = walk[-1]\n        cur_neighbors = list(G.neighbors(cur_node))\n\n        if len(cur_neighbors) > 0:\n            if len(walk) == 1:\n                walk.append(random.choice(cur_neighbors))\n            else:\n                prev_node = walk[-2]\n\n                probability = []\n                for neighbor in cur_neighbors:\n                    if neighbor == prev_node:\n                        # Return parameter \n                        probability.append(1/p)\n                    elif G.has_edge(neighbor, prev_node):\n                        # Stay parameter \n                        probability.append(1)\n                    else:\n                        # In-out parameter \n                        probability.append(1/q)\n\n                probability = np.array(probability)\n                probability = probability / probability.sum()  # normalize\n\n                next_node = np.random.choice(cur_neighbors, p=probability)\n                walk.append(next_node)\n        else:\n            break\n\n    return walk","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:44:58.152124Z","iopub.execute_input":"2024-05-15T10:44:58.152571Z","iopub.status.idle":"2024-05-15T10:44:58.163704Z","shell.execute_reply.started":"2024-05-15T10:44:58.152538Z","shell.execute_reply":"2024-05-15T10:44:58.162522Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generate_walks(G, num_walks, walk_length, p=1, q=1):\n    walks = []\n    nodes = list(G.nodes())\n    for _ in range(num_walks):\n        random.shuffle(nodes)  # to ensure randomness\n        for node in nodes:\n            walk_from_node = biased_random_walk(G, node, walk_length, p, q)\n            walks.append(walk_from_node)\n    return walks","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:45:00.716080Z","iopub.execute_input":"2024-05-15T10:45:00.716535Z","iopub.status.idle":"2024-05-15T10:45:00.723621Z","shell.execute_reply.started":"2024-05-15T10:45:00.716500Z","shell.execute_reply":"2024-05-15T10:45:00.722293Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#!pip install pygsp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def creating_model(G):\n    walks = generate_walks(G, num_walks=10, walk_length=20, p=9, q=1)\n    filtered_walks = [walk for walk in walks if len(walk) >= 5]\n\n    # to String  (for Word2Vec input)\n    walks = [[str(node) for node in walk] for walk in walks]\n\n    # Word2Vec train\n    model = Word2Vec(walks, vector_size=128, window=5, min_count=0,  hs=1, sg=1, workers=4, epochs=10)\n\n    # node embedding extract\n    embeddings = {node_id: model.wv[node_id] for node_id in model.wv.index_to_key}\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:45:03.121367Z","iopub.execute_input":"2024-05-15T10:45:03.121835Z","iopub.status.idle":"2024-05-15T10:45:03.131014Z","shell.execute_reply.started":"2024-05-15T10:45:03.121801Z","shell.execute_reply":"2024-05-15T10:45:03.129615Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"G1, node_index1 = creating_graph(X1_train)\nG4, node_index4 = creating_graph(X4_train)\nG5, node_index5 = creating_graph(X5_train)\nG6, node_index6 = creating_graph(X6_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:45:06.109808Z","iopub.execute_input":"2024-05-15T10:45:06.110260Z","iopub.status.idle":"2024-05-15T10:45:21.750403Z","shell.execute_reply.started":"2024-05-15T10:45:06.110225Z","shell.execute_reply":"2024-05-15T10:45:21.748833Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#model1 = creating_model(G1)\n#model4 = creating_model(G4)\n#model5 = creating_model(G5)\nmodel6 = creating_model(G6)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:48:21.736264Z","iopub.execute_input":"2024-05-15T10:48:21.737759Z","iopub.status.idle":"2024-05-15T11:07:57.585849Z","shell.execute_reply.started":"2024-05-15T10:48:21.737702Z","shell.execute_reply":"2024-05-15T11:07:57.583901Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model1 = creating_model(G1)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model4 = creating_model(G4)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model5 = creating_model(G5)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model6 \u001b[38;5;241m=\u001b[39m \u001b[43mcreating_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG6\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mcreating_model\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreating_model\u001b[39m(G):\n\u001b[0;32m----> 2\u001b[0m     walks \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_walks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     filtered_walks \u001b[38;5;241m=\u001b[39m [walk \u001b[38;5;28;01mfor\u001b[39;00m walk \u001b[38;5;129;01min\u001b[39;00m walks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(walk) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# to String  (for Word2Vec input)\u001b[39;00m\n","Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mgenerate_walks\u001b[0;34m(G, num_walks, walk_length, p, q)\u001b[0m\n\u001b[1;32m      5\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(nodes)  \u001b[38;5;66;03m# to ensure randomness\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m----> 7\u001b[0m         walk_from_node \u001b[38;5;241m=\u001b[39m \u001b[43mbiased_random_walk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         walks\u001b[38;5;241m.\u001b[39mappend(walk_from_node)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m walks\n","Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mbiased_random_walk\u001b[0;34m(G, start_node, walk_length, p, q)\u001b[0m\n\u001b[1;32m     21\u001b[0m         probability\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m# In-out parameter \u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         \u001b[43mprobability\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m probability \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(probability)\n\u001b[1;32m     27\u001b[0m probability \u001b[38;5;241m=\u001b[39m probability \u001b[38;5;241m/\u001b[39m probability\u001b[38;5;241m.\u001b[39msum()  \u001b[38;5;66;03m# normalize\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#embeddings1 = {node_id: model1.wv[node_id] for node_id in model1.wv.index_to_key}\n#embeddings4 = {node_id: model4.wv[node_id] for node_id in model4.wv.index_to_key}\n#embeddings5 = {node_id: model5.wv[node_id] for node_id in model5.wv.index_to_key}\nembeddings6 = {node_id: model6.wv[node_id] for node_id in model6.wv.index_to_key}","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:25.819158Z","iopub.execute_input":"2024-05-15T10:46:25.819827Z","iopub.status.idle":"2024-05-15T10:46:25.826731Z","shell.execute_reply.started":"2024-05-15T10:46:25.819783Z","shell.execute_reply":"2024-05-15T10:46:25.825515Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_user_embedding(user_id, embeddings):\n    return embeddings[str(user_id)]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:28.936819Z","iopub.execute_input":"2024-05-15T10:46:28.937474Z","iopub.status.idle":"2024-05-15T10:46:28.943019Z","shell.execute_reply.started":"2024-05-15T10:46:28.937418Z","shell.execute_reply":"2024-05-15T10:46:28.941423Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_rated_items(user_id, df, item, items):\n    return df[df['Phone_new'] == user_id][item]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:30.707752Z","iopub.execute_input":"2024-05-15T10:46:30.708408Z","iopub.status.idle":"2024-05-15T10:46:30.714084Z","shell.execute_reply.started":"2024-05-15T10:46:30.708376Z","shell.execute_reply":"2024-05-15T10:46:30.712544Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def calculate_similarities(user_id, df, embeddings, items):\n    for item in items:\n        rated_items = get_rated_items(user_id, df, item, items)\n    user_embedding = get_user_embedding(user_id, embeddings)\n\n    item_similarities = []\n    for item_id in items:\n        if item_id not in rated_items:  \n            item_embedding = embeddings[item_id]\n            similarity = cosine_similarity([user_embedding], [item_embedding])[0][0]\n            item_similarities.append((item_id, similarity))\n\n    return item_similarities","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:32.762332Z","iopub.execute_input":"2024-05-15T10:46:32.762774Z","iopub.status.idle":"2024-05-15T10:46:32.771090Z","shell.execute_reply.started":"2024-05-15T10:46:32.762741Z","shell.execute_reply":"2024-05-15T10:46:32.769524Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def recommend_items(user_id, df, embeddings, items, num_items=5):\n    for item in items:\n        rated_items = get_rated_items(user_id, df, item, items)\n    \n    #print(f\"User {user_id} has purchased:\")\n    #print(rated_items)\n    \n    item_similarities = calculate_similarities(user_id, df, embeddings, items)\n\n    recommended_items = sorted(item_similarities, key=lambda x: x[1], reverse=True)[:num_items]\n\n    #print(f\"\\nRecommended items for user {user_id}:\")\n    #print(recommended_items)\n    return recommended_items","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:36.210250Z","iopub.execute_input":"2024-05-15T10:46:36.210670Z","iopub.status.idle":"2024-05-15T10:46:36.217972Z","shell.execute_reply.started":"2024-05-15T10:46:36.210640Z","shell.execute_reply":"2024-05-15T10:46:36.216731Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"items = ['%TN_Автотовары', '%TN_Аксессуары', '%TN_Детские товары', '%TN_Игры, софт и развлечения', '%TN_Климат', '%TN_Крупная бытовая техника', '%TN_Мебель', '%TN_Мелкая бытовая техника', '%TN_Сделай сам', '%TN_Спорт и активный отдых', '%TN_ТВ-Аудио', '%TN_Товары для дома', '%TN_Услуги', '%TN_Хобби, досуг', '%TN_Цифровая Техника', '%TN_Элитная техника']\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:53.540612Z","iopub.execute_input":"2024-05-15T10:46:53.541102Z","iopub.status.idle":"2024-05-15T10:46:53.547457Z","shell.execute_reply.started":"2024-05-15T10:46:53.541065Z","shell.execute_reply":"2024-05-15T10:46:53.546325Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#recommends1 = recommend_items(0, df1, embeddings1, items, num_items=16)\n#recommends4 = recommend_items(0, df4, embeddings4, items, num_items=16)\nrecommends5 = recommend_items(0, df5, embeddings5, items, num_items=16)\n#recommends6 = recommend_items(0, df6, embeddings6, items, num_items=16)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:54.986840Z","iopub.execute_input":"2024-05-15T10:46:54.987393Z","iopub.status.idle":"2024-05-15T10:46:55.121564Z","shell.execute_reply.started":"2024-05-15T10:46:54.987350Z","shell.execute_reply":"2024-05-15T10:46:55.119151Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#recommends1 = recommend_items(0, df1, embeddings1, items, num_items=16)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#recommends4 = recommend_items(0, df4, embeddings4, items, num_items=16)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m recommends5 \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_items\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#recommends6 = recommend_items(0, df6, embeddings6, items, num_items=16)\u001b[39;00m\n","Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mrecommend_items\u001b[0;34m(user_id, df, embeddings, items, num_items)\u001b[0m\n\u001b[1;32m      3\u001b[0m     rated_items \u001b[38;5;241m=\u001b[39m get_rated_items(user_id, df, item, items)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#print(f\"User {user_id} has purchased:\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#print(rated_items)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m item_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_similarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m recommended_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(item_similarities, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:num_items]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(f\"\\nRecommended items for user {user_id}:\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#print(recommended_items)\u001b[39;00m\n","Cell \u001b[0;32mIn[15], line 9\u001b[0m, in \u001b[0;36mcalculate_similarities\u001b[0;34m(user_id, df, embeddings, items)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_id \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m rated_items:  \n\u001b[0;32m----> 9\u001b[0m         item_embedding \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m         similarity \u001b[38;5;241m=\u001b[39m cosine_similarity([user_embedding], [item_embedding])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m         item_similarities\u001b[38;5;241m.\u001b[39mappend((item_id, similarity))\n","\u001b[0;31mKeyError\u001b[0m: '%TN_Автотовары'"],"ename":"KeyError","evalue":"'%TN_Автотовары'","output_type":"error"}]},{"cell_type":"code","source":"recommends1, recommends4, recommends5, recommends6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1_test[items]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"relevance_score1 = [x[1] for x in recommends1]\nrelevance_score1 = relevance_score1\nrelevance_score1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_at_k(scores, true_relevance, k):\n    \n    num_users = len(scores)\n    ap_scores = []\n\n    for i in range(num_users):\n        # Sort the predicted scores by value\n        sorted_scores = sorted(enumerate(scores[i]), key=lambda x: x[1], reverse=True)\n        # Get the top k predicted items\n        top_k_predicted_items = [x[0] for x in sorted_scores[:k]]\n        # Calculate the average precision\n        num_relevant_items = sum(1 for j in range(len(true_relevance[i])) if true_relevance[i][j] > 0)\n        relevant_count = 0\n        ap = 0\n        for j in range(k):\n            if true_relevance[i][top_k_predicted_items[j]] > 0:\n                relevant_count += 1\n                ap += relevant_count / (j + 1)\n        ap_scores.append(ap / min(num_relevant_items, k))\n\n    # Calculate the MAP@K score\n    map_k = np.mean(ap_scores)\n    return map_k","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maps = []\nfor i in range(len(X1_test)):\n    true_relevance = X1_test[items].iloc[i].values.tolist()\n    for i in range(len(true_relevance)):\n        if true_relevance[i] > 0:\n            true_relevance[i] = 1\n    map_k = map_at_k([relevance_score1], [true_relevance], 10)\n    maps.append(map_k)\n# for i in range(len(maps)):\n#     if maps[i] == 0:\n#         maps[i] = 1\nnp.mean(maps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport networkx as nx\nimport scipy.sparse as sp\n\nclass GraphAttentionLayer(nn.Module):\n    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n        super(GraphAttentionLayer, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.alpha = alpha\n        self.concat = concat\n        self.dropout = dropout\n        \n        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n        \n        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n        \n        self.leakyrelu = nn.LeakyReLU(self.alpha)\n        \n    def forward(self, input, adj):\n        h = torch.matmul(input, self.W)\n        N = h.size()[0]\n        \n        a_input = torch.cat([h.repeat(1, N).view(N*N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2*self.out_features)\n        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n        \n        zero_vec = -9e15*torch.ones_like(e)\n        attention = torch.where(adj > 0, e, zero_vec)\n        attention = F.softmax(attention, dim=1)\n        attention = F.dropout(attention, self.dropout, training=self.training)\n        h_prime = torch.matmul(attention, h)\n        \n        if self.concat:\n            return F.elu(h_prime)\n        else:\n            return h_prime\n\nclass GAT(nn.Module):\n    def __init__(self, nfeat, nhid, nclass, dropout=0.6, alpha=0.2, nheads=8):\n        super(GAT, self).__init__()\n        self.dropout = dropout\n        \n        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n        for i, attention in enumerate(self.attentions):\n            self.add_module('attention_{}'.format(i), attention)\n        \n        self.out_att = GraphAttentionLayer(nhid*nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n        \n    def forward(self, x, adj):\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = F.elu(self.out_att(x, adj))\n        return F.log_softmax(x, dim=1)\n\n# Example usage\nG = G6\n# Generate a random graph using NetworkX\nadj = nx.adjacency_matrix(G)\n\n# Convert adjacency matrix to a PyTorch dense tensor\nadj_tensor = torch.FloatTensor(adj.todense())\n\n# Define node features (random in this example)\nnode_features = torch.randn(G.number_of_nodes(), 16) # Use the number of nodes from your graph\n\n# Initialize the GAT model\nmodel = GAT(nfeat=16, nhid=8, nclass=2, dropout=0.6, alpha=0.2, nheads=8)\n\n# Forward pass\n\nembeddings = model(node_features, adj_tensor)\nembeddings_dict = {node_id: embeddings[index].detach().numpy() for node_id, index in node_index6.items()}\n\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef recommend_items(user_id, embeddings_dict, top_n=5):\n    user_embedding = embeddings_dict[user_id]\n    item_embeddings = [embedding for node_id, embedding in embeddings_dict.items() if node_id != user_id and node_id.startswith('%')]\n    \n    similarities = cosine_similarity([user_embedding], item_embeddings)\n    top_indices = np.argsort(similarities[0])[::-1][:top_n]\n    \n    recommended_items = [(list(embeddings_dict.keys())[i], similarities[0][i]) for i in top_indices]\n    return recommended_items\n\n# Example usage\nuser_id = '000-000'  \nrecommended_items = recommend_items(user_id, embeddings_dict)\n\nmaps = []\nfor i in range(len(X5_test)):\n    true_relevance = X5_test[items].iloc[i].values.tolist()\n    for i in range(len(true_relevance)):\n        if true_relevance[i] > 0:\n            true_relevance[i] = 1\n    map_k = map_at_k([recommended_items], [true_relevance], 5)\n    maps.append(map_k)\n# for i in range(len(maps)):\n#     if maps[i] == 0:\n#         maps[i] = 1\nnp.mean(maps)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:10:23.566736Z","iopub.execute_input":"2024-05-15T11:10:23.567261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndef recommend_items(user_id, embeddings_dict, top_n=10):\n    user_embedding = embeddings_dict[user_id]\n    item_embeddings = [embedding for node_id, embedding in embeddings_dict.items() if node_id != user_id and node_id.startswith('%')]\n    \n    similarities = cosine_similarity([user_embedding], item_embeddings)\n    top_indices = np.argsort(similarities[0])[::-1][:top_n]\n    \n    recommended_items = [(list(embeddings_dict.keys())[i], similarities[0][i]) for i in top_indices]\n    return recommended_items","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport networkx as nx\nimport scipy.sparse as sp\n\n\nclass GraphConvolution(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(GraphConvolution, self).__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n        nn.init.xavier_uniform_(self.weight)\n\n    def forward(self, input, adj):\n        support = torch.matmul(input, self.weight)\n        output = torch.matmul(adj, support)\n        return output\n\nclass GCN(nn.Module):\n    def __init__(self, nfeat, nhid, nclass):\n        super(GCN, self).__init__()\n        self.gc1 = GraphConvolution(nfeat, nhid)\n        self.gc2 = GraphConvolution(nhid, nclass)\n\n    def forward(self, x, adj):\n        x = F.relu(self.gc1(x, adj))\n        x = self.gc2(x, adj)\n        return F.log_softmax(x, dim=1)\n\n\n\nGr = G6\nadj = nx.adjacency_matrix(Gr)\n\n# Convert adjacency matrix to a PyTorch sparse tensor\nadj_tensor = torch.FloatTensor(adj.todense())\n\n# Define node features (random in this example)\nnode_features = torch.randn(Gr.number_of_nodes(), 16) # Use the number of nodes from your graph\n\n# Initialize the GCN model\nmodel = GCN(nfeat=16, nhid=8, nclass=2)\n\n# Forward pass to obtain embeddings\nembeddings = model(node_features, adj_tensor)\n\nembeddings_dict = {node_id: embeddings[index].detach().numpy() for node_id, index in node_index6.items()}\n\nuser_id = \"000-000\"\nrecommended_items = recommend_items(user_id, embeddings_dict)\nrecommended_items ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:09:11.019028Z","iopub.execute_input":"2024-05-15T11:09:11.019541Z","iopub.status.idle":"2024-05-15T11:09:15.254056Z","shell.execute_reply.started":"2024-05-15T11:09:11.019497Z","shell.execute_reply":"2024-05-15T11:09:15.252267Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m embeddings_dict \u001b[38;5;241m=\u001b[39m {node_id: embeddings[index]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m node_id, index \u001b[38;5;129;01min\u001b[39;00m node_index6\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     51\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m000-000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m recommended_items \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m recommended_items \n","\u001b[0;31mTypeError\u001b[0m: recommend_items() missing 2 required positional arguments: 'embeddings' and 'items'"],"ename":"TypeError","evalue":"recommend_items() missing 2 required positional arguments: 'embeddings' and 'items'","output_type":"error"}]},{"cell_type":"code","source":"maps = []\nfor i in range(len(X1_test)):\n    true_relevance = X1_test[items].iloc[i].values.tolist()\n#     for i in range(len(true_relevance)):\n#         if true_relevance[i] > 0:\n#             true_relevance[i] = 1\n    map_k = map_at_k([recommended_items], [true_relevance], 10)\n    maps.append(map_k)\n# for i in range(len(maps)):\n#     if maps[i] == 0:\n#         maps[i] = 1\nnp.mean(maps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}